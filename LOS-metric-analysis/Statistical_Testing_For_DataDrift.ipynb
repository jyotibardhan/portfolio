{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. One Sample K-S Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for code reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "#generate dataset of 100 values that follow a Poisson distribution with mean=5\n",
    "data = pd.DataFrame(np.random.poisson(lam=5,size=100), columns=['arrival_time'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kolmogorov-Smirnov test to check if the arrival_time is from a normal distribution\n",
    "\n",
    "test_obj = stats.kstest(data, 'norm',N=100)\n",
    "test_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_obj.pvalue,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Two Sample K-S Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for code reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "#generate dataset of 100 values that follow a Poisson distribution\n",
    "data1 = pd.DataFrame(np.random.poisson(lam=5,size=100), columns=['arrival_time'])\n",
    "# data2 = pd.DataFrame(np.random.normal(7,2,100), columns=['arrival_time'])\n",
    "data2 = pd.DataFrame(np.random.poisson(lam=5,size=100), columns=['arrival_time'])\n",
    "print(data1.shape)\n",
    "display(data1.head())\n",
    "print(data2.shape)\n",
    "display(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kolmogorov-Smirnov test to check if the arrival_time from two experiments is same or not\n",
    "\n",
    "test_obj = stats.ks_2samp(data1.arrival_time, data2.arrival_time)\n",
    "test_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(test_obj.pvalue,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''Calculate the PSI (population stability index) across all variables\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for code reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "#generate dataset of 100 values that follow a Poisson distribution with mean=5\n",
    "data1 = pd.DataFrame(np.random.poisson(lam=5,size=100), columns=['arrival_time'])\n",
    "# data1 = pd.DataFrame(np.random.normal(7,2,100), columns=['arrival_time'])\n",
    "data2 = pd.DataFrame(np.random.normal(7,2,100), columns=['arrival_time'])\n",
    "print(data1.shape)\n",
    "display(data1.head())\n",
    "print(data2.shape)\n",
    "display(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_val = calculate_psi(data1.arrival_time,data2.arrival_time)\n",
    "print(psi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculating the kl divergence between two mass functions\n",
    "from math import log2\n",
    "\n",
    "# calculate the kl divergence\n",
    "def kl_divergence(p, q):\n",
    "\treturn sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))\n",
    "\n",
    "# define distributions\n",
    "p = [0.10, 0.40, 0.50]\n",
    "q = [0.80, 0.15, 0.05]\n",
    "# calculate (P || Q)\n",
    "kl_pq = kl_divergence(p, q)\n",
    "print('KL(P || Q): %.3f bits' % kl_pq)\n",
    "# calculate (Q || P)\n",
    "kl_qp = kl_divergence(q, p)\n",
    "print('KL(Q || P): %.3f bits' % kl_qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculating the kl divergence (relative entropy) with scipy\n",
    "from scipy.special import rel_entr\n",
    "# define distributions\n",
    "p = [0.10, 0.40, 0.50]\n",
    "q = [0.80, 0.15, 0.05]\n",
    "# calculate (P || Q)\n",
    "kl_pq = rel_entr(p, q)\n",
    "print('KL(P || Q): %.3f nats' % sum(kl_pq))\n",
    "# calculate (Q || P)\n",
    "kl_qp = rel_entr(q, p)\n",
    "print('KL(Q || P): %.3f nats' % sum(kl_qp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculating the js divergence between two mass functions\n",
    "from math import log2\n",
    "from math import sqrt\n",
    "from numpy import asarray\n",
    "\n",
    "# calculate the kl divergence\n",
    "def kl_divergence(p, q):\n",
    "\treturn sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))\n",
    "\n",
    "# calculate the js divergence\n",
    "def js_divergence(p, q):\n",
    "\tm = 0.5 * (p + q)\n",
    "\treturn 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
    "\n",
    "# define distributions\n",
    "p = asarray([0.10, 0.40, 0.50])\n",
    "q = asarray([0.80, 0.15, 0.05])\n",
    "# calculate JS(P || Q)\n",
    "js_pq = js_divergence(p, q)\n",
    "print('JS(P || Q) divergence: %.3f bits' % js_pq)\n",
    "print('JS(P || Q) distance: %.3f' % sqrt(js_pq))\n",
    "# calculate JS(Q || P)\n",
    "js_qp = js_divergence(q, p)\n",
    "print('JS(Q || P) divergence: %.3f bits' % js_qp)\n",
    "print('JS(Q || P) distance: %.3f' % sqrt(js_qp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the jensen-shannon distance metric\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from numpy import asarray\n",
    "# define distributions\n",
    "p = asarray([0.10, 0.40, 0.50])\n",
    "q = asarray([0.80, 0.15, 0.05])\n",
    "# calculate JS(P || Q)\n",
    "js_pq = jensenshannon(p, q, base=2)\n",
    "print('JS(P || Q) Distance: %.3f' % js_pq)\n",
    "# calculate JS(Q || P)\n",
    "js_qp = jensenshannon(q, p, base=2)\n",
    "print('JS(Q || P) Distance: %.3f' % js_qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for code reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "#generate dataset of 100 values that follow a Poisson distribution with mean=5\n",
    "data1 = pd.DataFrame(np.random.poisson(lam=5,size=100), columns=['arrival_time'])\n",
    "data2 = pd.DataFrame(np.random.normal(7,2,100), columns=['arrival_time'])\n",
    "print(data1.shape)\n",
    "display(data1.head())\n",
    "print(data2.shape)\n",
    "display(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the first Wasserstein distance between two 1D distributions.\n",
    "\n",
    "wd = stats.wasserstein_distance(data1.arrival_time,data2.arrival_time)\n",
    "print(\"For different distributions: \"+str(wd))\n",
    "\n",
    "wd = stats.wasserstein_distance(data1.arrival_time,data1.arrival_time)\n",
    "print(\"For same distributions: \"+str(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating reference and target dataframe with categorical column\n",
    "d1 = ['A','A','A','A','B','B','C','C','C']\n",
    "d2 = ['A','A','B','B','B','B','B','C','C']\n",
    "data_ref = pd.DataFrame(d1, columns=['ticket_category_ref'])\n",
    "print(data_ref.shape)\n",
    "display(data_ref)\n",
    "\n",
    "data_target = pd.DataFrame(d2, columns=['ticket_category_tar'])\n",
    "print(data_target.shape)\n",
    "display(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(data_ref.ticket_category_ref,data_target.ticket_category_tar)\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square test of independence\n",
    "# if p < 0.05 then the two categories are not independnt of each other\n",
    "chi2_stat, pvalue, df, expected_freq = stats.chi2_contingency(cross_tab)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square goodness of fit test\n",
    "# Make sure you have the frequency of each categories in the same order in both observed and expected\n",
    "# if p < 0.05 then the two frequencies are not from same distribution\n",
    "expected = data_target.groupby('ticket_category_tar')['ticket_category_tar'].count().values\n",
    "observed = data_ref.groupby('ticket_category_ref')['ticket_category_ref'].count().values \n",
    "\n",
    "chi2_stat, pvalue = stats.chisquare(f_obs=observed,f_exp=expected)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target.groupby('ticket_category_tar')['ticket_category_tar'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref.groupby('ticket_category_ref')['ticket_category_ref'].count().values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "415410f39d953828783f6475a37c88806807d7c4c38ec2bd54e842e91eef5ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
