{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle \n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import alibi \n",
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "\n",
    "import sqlalchemy\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import *\n",
    "\n",
    "import xgboost\n",
    "from datetime import datetime, timedelta\n",
    "import time  \n",
    "import pytz    \n",
    "tz_NY = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "import snowflake_creds\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection engine (way 1)\n",
    "engine = create_engine(URL(\n",
    "        account=\"cr21746.ap-south-1\",\n",
    "        user= snowflake_creds.USER_NAME,\n",
    "        password= snowflake_creds.PASSWORD,\n",
    "        role=\"ACCOUNTADMIN\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"HEALTHDB\",\n",
    "        schema=\"HEALTHSCHEMA\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b161b",
   "metadata": {},
   "source": [
    "## Creating the Model and Data drift detector object from Training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71166283",
   "metadata": {},
   "source": [
    "#### Data Drift detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1db59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "SELECT CASE_ID,\n",
    "           COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "           COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "           COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "           COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "           COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "           COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "           COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "           COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "           COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "           PATIENTID,\n",
    "           COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "           COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "           COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "           COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "           COALESCE(AGE,'None') AS AGE,\n",
    "           COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "           ADMISSION_DATE,\n",
    "           DISCHARGE_DATE\n",
    "\n",
    "    FROM HEALTHDB.HEALTHSCHEMA.HEALTH_DATA\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "with engine.connect() as conn:\n",
    "    df_train = pd.DataFrame(pd.read_sql(query,conn))\n",
    "    df_train.columns = [col.upper() for col in df_train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02396ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the numerical and categorical columns for creating the datadrift object\n",
    "num_columns = ['AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL','VISITORS_WITH_PATIENT','ADMISSION_DEPOSIT']\n",
    "id_columns = ['CASE_ID','PATIENTID','ADMISSION_DATE','DISCHARGE_DATE']\n",
    "cat_columns = [col for col in df_train.columns.tolist() if col not in num_columns+id_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44013a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[num_columns + cat_columns]\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_indices = np.arange(3,15)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category dict for the driftdetector to identify unique categories\n",
    "categories_per_feature = {f: None for f in cat_indices}\n",
    "categories_per_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the detector\n",
    "cd = TabularDrift(X_train.values, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using pickle to save and load it the trained detector\n",
    "# with open('Trained_Drift_Detector.pkl','wb') as F:\n",
    "#     pickle.dump(cd,F)\n",
    "\n",
    "with open('Trained_Drift_Detector.pkl','rb') as F:\n",
    "    trained_drift_model = pickle.load(F)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ace8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_drift_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09585ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trained_drift_model.predict(X_train.values)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27570f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are interested in individual feature-wise drift, this is also possible:\n",
    "fpreds = trained_drift_model.predict(X_train.values, drift_type='feature')\n",
    "fpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(trained_drift_model.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    # print(f, stat)\n",
    "    fname = X_train.columns.tolist()[f]\n",
    "    # print(f, fname)\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['Time Period'] = [str('2023-01-01') + ' to ' + str('2023-01-07')]*len(X_train.columns.tolist())\n",
    "temp['Features'] = X_train.columns.tolist()\n",
    "temp['Is Drift'] = fpreds['data']['is_drift']\n",
    "temp['Stat Test'] = temp['Features'].apply(lambda x: 'Chi2' if x in cat_columns else 'K-S')\n",
    "temp['Stats Value'] = fpreds['data']['distance']\n",
    "temp['P-value'] = fpreds['data']['p_val']\n",
    "print(temp.shape)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eaa55d",
   "metadata": {},
   "source": [
    "##### Creating a noise in the train data to check if drift detector is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train.copy()\n",
    "temp.loc[:5,'HOSPITAL_CODE'] = 100\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are interested in individual feature-wise drift, this is also possible:\n",
    "fpreds = trained_drift_model.predict(temp.values, drift_type='feature')\n",
    "fpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806de447",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(trained_drift_model.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    # print(f, stat)\n",
    "    fname = temp.columns.tolist()[f]\n",
    "    # print(f, fname)\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f976ad",
   "metadata": {},
   "source": [
    "#### Data Drift Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251eafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_monitoring_batch_query(a):\n",
    "    query = f\"\"\"\n",
    "\n",
    "        SELECT CASE_ID,\n",
    "               COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "               COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "               COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "               COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "               COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL_X,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "               COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "               COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "               COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "               COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "               PATIENTID,\n",
    "               COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "               COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "               COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "               COALESCE(VISITORS_WITH_PATIENT_X,0) AS VISITORS_WITH_PATIENT,\n",
    "               COALESCE(AGE,'None') AS AGE,\n",
    "               COALESCE(ADMISSION_DEPOSIT_X,0) AS ADMISSION_DEPOSIT,\n",
    "               ADMISSION_DATE,\n",
    "               DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTHDB.HEALTHSCHEMA.TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "            WHERE ADMISSION_DATE >= CURRENT_DATE-144+{a*7} AND ADMISSION_DATE < CURRENT_DATE-144+{(a+1)*7}        \n",
    "\n",
    "        \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_monitoring(batch_id):\n",
    "    # Loading the train data\n",
    "    with engine.connect() as conn:\n",
    "        batch_df = pd.DataFrame(pd.read_sql(data_monitoring_batch_query(batch_id),conn))\n",
    "        batch_df.columns = [col.upper() for col in batch_df.columns.tolist()]\n",
    "    \n",
    "    # Getting the numerical and categorical columns for creating the datadrift object\n",
    "    num_columns = ['AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL','VISITORS_WITH_PATIENT','ADMISSION_DEPOSIT']\n",
    "    id_columns = ['CASE_ID','PATIENTID','ADMISSION_DATE','DISCHARGE_DATE']\n",
    "    cat_columns = [col for col in batch_df.columns.tolist() if col not in num_columns+id_columns]\n",
    "    \n",
    "    # Getting the final prepared data\n",
    "    batch_final = batch_df[num_columns + cat_columns]\n",
    "    \n",
    "    # Loading the Trained data drift detector\n",
    "    with open('Trained_Drift_Detector.pkl','rb') as F:\n",
    "        trained_drift_model = pickle.load(F)    \n",
    "    \n",
    "    # Checking for drift\n",
    "    # If you are interested in individual feature-wise drift, this is also possible:\n",
    "    fpreds = trained_drift_model.predict(batch_final.values, drift_type='feature')\n",
    "    \n",
    "    log_df = pd.DataFrame()\n",
    "    log_df['Time Period'] = ([str(batch_df['ADMISSION_DATE'].min()) + ' to ' + \n",
    "                              str(batch_df['ADMISSION_DATE'].max())]\n",
    "                              * len(batch_final.columns.tolist())\n",
    "                            )\n",
    "    log_df['Total Records'] = batch_df.shape[0]\n",
    "    log_df['Features'] = batch_final.columns.tolist()\n",
    "    log_df['Is Drift'] = fpreds['data']['is_drift']\n",
    "    log_df['Stat Test'] = log_df['Features'].apply(lambda x: 'Chi2' if x in cat_columns else 'K-S')\n",
    "    log_df['Stats Value'] = np.round(fpreds['data']['distance'])\n",
    "    log_df['P-value'] = np.round(fpreds['data']['p_val'])\n",
    "    \n",
    "    return log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monitoring(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_monitoring(0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.shape[0])\n",
    "print(t['Is Drift'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f61a94",
   "metadata": {},
   "source": [
    "### Model Drift detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833632cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the logging table in batches (7 days)\n",
    "# Using the predicted and actual LOS calculate the performance metrics dict\n",
    "# Then use the ref_metric_dict (from training) to compare with the current_metric_dict for model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18707a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection engine (way 1)\n",
    "engine = create_engine(URL(\n",
    "        account=\"cr21746.ap-south-1\",\n",
    "        user= snowflake_creds.USER_NAME,\n",
    "        password= snowflake_creds.PASSWORD,\n",
    "        role=\"ACCOUNTADMIN\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"HEALTHDB\",\n",
    "        schema=\"HEALTHSCHEMA\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea13c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check model drift\n",
    "def check_model_drift(ref_metric_dict,cur_metric_dict,type='classification',tol=0.1):\n",
    "    if type == 'classification':\n",
    "        precision_change = abs((cur_metric_dict['Precision']-ref_metric_dict['Precision'])/ref_metric_dict['Precision'])\n",
    "        recall_change = abs((cur_metric_dict['Recall']-ref_metric_dict['Recall'])/ref_metric_dict['Recall'])\n",
    "        roc_auc_change = abs((cur_metric_dict['Roc-Auc']-ref_metric_dict['Roc-Auc'])/ref_metric_dict['Roc-Auc'])\n",
    "\n",
    "        counter = 0\n",
    "        for i in [precision_change,recall_change,roc_auc_change]:\n",
    "            if i > tol:\n",
    "                counter += 1\n",
    "\n",
    "        if counter > 0:\n",
    "            print(\"ALERT! There is a model drift.\")\n",
    "            print(\"Change in Precision: \"+ str(np.round(100*precision_change,2))+\"%\")\n",
    "            print(\"Change in Recall: \"+ str(np.round(100*recall_change,2))+\"%\")\n",
    "            print(\"Change in Roc-Auc: \"+ str(np.round(100*roc_auc_change,2))+\"%\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"There is no model drift.\")\n",
    "            return 0\n",
    "\n",
    "    elif type == 'regression':\n",
    "        rmse_change = abs((cur_metric_dict['RMSE']-ref_metric_dict['RMSE'])/ref_metric_dict['RMSE'])\n",
    "        mae_change = abs((cur_metric_dict['MAE']-ref_metric_dict['MAE'])/ref_metric_dict['MAE'])\n",
    "        \n",
    "        counter = 0\n",
    "        for i in [rmse_change,mae_change]:\n",
    "            if i > tol:\n",
    "                counter += 1\n",
    "\n",
    "        if counter > 0:\n",
    "            print(\"ALERT! There is a model drift.\")\n",
    "            RMSE_CHANGE = np.round(100*rmse_change,2)\n",
    "            MAE_CHANGE = np.round(100*mae_change,2)\n",
    "            print(\"Change in RMSE: \"+ str(np.round(100*rmse_change,2))+\"%\")\n",
    "            print(\"Change in MAE: \"+ str(np.round(100*mae_change,2))+\"%\")\n",
    "            return 1, RMSE_CHANGE, MAE_CHANGE\n",
    "        else:\n",
    "            print(\"There is no model drift.\")\n",
    "            RMSE_CHANGE = 'NONE'\n",
    "            MAE_CHANGE = 'NONE'\n",
    "            return 0, RMSE_CHANGE, MAE_CHANGE\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_monitoring_batch_query(a):\n",
    "    query_sim = f\"\"\"\n",
    "\n",
    "        SELECT *\n",
    "        FROM TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "        WHERE ADMISSION_DATE >= CURRENT_DATE-144+{a*7} AND ADMISSION_DATE < CURRENT_DATE-144+{(a+1)*7}\n",
    "        \n",
    "    \"\"\"\n",
    "    return query_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b99b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_monitoring_batch_query(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16131c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "with engine.connect() as conn:\n",
    "    batch_df = pd.DataFrame(pd.read_sql(model_monitoring_batch_query(0),conn))\n",
    "    batch_df.columns = [col.upper() for col in batch_df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e81d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_df.shape)\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the current performance dict (from scoring)\n",
    "\n",
    "actual = batch_df['LOS_X']\n",
    "predicted = batch_df['PREDICTED_LOS']\n",
    "\n",
    "rmse = np.sqrt(metrics.mean_squared_error(actual,predicted))\n",
    "mae = np.sqrt(metrics.mean_absolute_error(actual,predicted))\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)\n",
    "\n",
    "scoring_ref_metrics = {}\n",
    "scoring_ref_metrics['RMSE'] = rmse\n",
    "scoring_ref_metrics['MAE'] = mae #+ 0.2*mae\n",
    "print(scoring_ref_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f18964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the reference performance dict (from training)\n",
    "\n",
    "with open('MODEL_XGB_PERFM_METRICS.pkl', 'rb') as F:\n",
    "    model_ref_metric = pickle.load(F)\n",
    "\n",
    "model_ref_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_drift(model_ref_metric,scoring_ref_metrics,type='regression',tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_monitoring(batch_id):\n",
    "    # Loading the train data\n",
    "    with engine.connect() as conn:\n",
    "        batch_df = pd.DataFrame(pd.read_sql(model_monitoring_batch_query(batch_id),conn))\n",
    "        batch_df.columns = [col.upper() for col in batch_df.columns.tolist()]\n",
    "    \n",
    "#     print(batch_df.shape)\n",
    "    \n",
    "    # Creating the current performance dict (from scoring)\n",
    "    actual = batch_df['LOS_X']\n",
    "    predicted = batch_df['PREDICTED_LOS']\n",
    "\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(actual,predicted))\n",
    "    mae = np.sqrt(metrics.mean_absolute_error(actual,predicted))\n",
    "#     print(\"RMSE: \", rmse)\n",
    "#     print(\"MAE: \", mae)\n",
    "\n",
    "    scoring_ref_metrics = {}\n",
    "    scoring_ref_metrics['RMSE'] = rmse\n",
    "    scoring_ref_metrics['MAE'] = mae #+ 0.2*mae\n",
    "#     print(scoring_ref_metrics)\n",
    "    \n",
    "    \n",
    "    # Loading the reference performance dict (from training)\n",
    "    with open('MODEL_XGB_PERFM_METRICS.pkl', 'rb') as F:\n",
    "        model_ref_metric = pickle.load(F)\n",
    "        \n",
    "#     print(model_ref_metric)\n",
    "    \n",
    "    # Check for model drift\n",
    "    model_drift, RMSE_CHANGE, MAE_CHANGE = check_model_drift(model_ref_metric,scoring_ref_metrics,type='regression',tol=0.1)\n",
    "    \n",
    "    # Log values\n",
    "    log = {}\n",
    "    log['Time Period'] = str(batch_df['ADMISSION_DATE'].min()) + ' to ' + str(batch_df['ADMISSION_DATE'].max())\n",
    "    log['Total Records'] = batch_df.shape[0]\n",
    "    log['Scoring Metrics'] = scoring_ref_metrics\n",
    "    log['Training Metrics'] = model_ref_metric\n",
    "    log['Model Drift IND'] = model_drift\n",
    "    log['RMSE Change'] = RMSE_CHANGE\n",
    "    log['MAE Change'] = MAE_CHANGE\n",
    "    \n",
    "    return log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a671318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_monitoring(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3876a2a",
   "metadata": {},
   "source": [
    "# Model Monitoring & Retraining Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_df = data_monitoring(0)\n",
    "model_log_dict = model_monitoring(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73fa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data drift condition\n",
    "data_log_df['Is Drift'].sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model drift condition\n",
    "model_log_dict['Model Drift IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max date for retraining \n",
    "max_date = model_log_dict['Time Period'].split(' ')[2]\n",
    "max_date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
